{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d3036",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "URL_ALERTA = \"http://localhost:6000/alerta/\"\n",
    "LOG_FILE = \"alert_log.txt\"\n",
    "DELAY_SEGUNDOS = 30\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def ajustar_low_light(frame: np.ndarray) -> np.ndarray:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    equalized = clahe.apply(gray)\n",
    "    processed = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)\n",
    "    return processed\n",
    "\n",
    "def is_punho_fechado(landmarks) -> bool:\n",
    "    wrist_y = landmarks[0].y\n",
    "    tip_ids = [8, 12, 16, 20]\n",
    "    return all(landmarks[i].y > wrist_y - 0.02 for i in tip_ids)\n",
    "\n",
    "def is_mao_levantada(landmarks) -> bool:\n",
    "    wrist_y = landmarks[0].y\n",
    "    tip_ids = [8, 12, 16, 20]\n",
    "    return all(landmarks[i].y < wrist_y - 0.05 for i in tip_ids)\n",
    "\n",
    "def emitir_som_alerta():\n",
    "    # Emite beep simples no console\n",
    "    print('\\a', end='', flush=True)\n",
    "\n",
    "def registrar_log(tipo: str, descricao: str):\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    linha = f\"{timestamp} | {tipo.upper()} | {descricao}\\n\"\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(linha)\n",
    "\n",
    "def enviar_alerta_servidor(payload: dict) -> bool:\n",
    "    try:\n",
    "        response = requests.post(URL_ALERTA, json=payload, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"[ERRO] Servidor retornou código {response.status_code}: {response.text}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRO] Falha ao enviar alerta ao servidor: {e}\")\n",
    "        return False\n",
    "\n",
    "def processar_fluxo(video_source):\n",
    "    cap = None\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(video_source)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(\"Não foi possível abrir a fonte de vídeo.\")\n",
    "\n",
    "        hands = mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "        alerta_enviado = False\n",
    "        last_alert_time = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"[INFO] Fim do vídeo ou falha na leitura da câmera.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            processed = ajustar_low_light(frame)\n",
    "            rgb = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            try:\n",
    "                results = hands.process(rgb)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Falha no MediaPipe.process(): {e}\")\n",
    "                results = None\n",
    "\n",
    "            alerta_atual = None\n",
    "\n",
    "            if results and results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    lm = hand_landmarks.landmark\n",
    "\n",
    "                    if is_mao_levantada(lm):\n",
    "                        alerta_atual = \"MÃO LEVANTADA\"\n",
    "                    elif is_punho_fechado(lm):\n",
    "                        alerta_atual = \"PUNHO FECHADO\"\n",
    "\n",
    "                    if alerta_atual:\n",
    "                        cv2.putText(\n",
    "                            frame,\n",
    "                            f\"ALERTA: {alerta_atual}\",\n",
    "                            (10, 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1, (0, 0, 255), 2\n",
    "                        )\n",
    "\n",
    "                        agora = time.time()\n",
    "                        if (not alerta_enviado) or (agora - last_alert_time) >= DELAY_SEGUNDOS:\n",
    "                            description = f\"{alerta_atual} detectado\"\n",
    "                            payload = {\n",
    "                                \"origem\": \"Camera_MediaPipe\",\n",
    "                                \"mensagem\": description,\n",
    "                                \"gravidade\": \"Alta\" if alerta_atual == \"PUNHO FECHADO\" else \"Normal\"\n",
    "                            }\n",
    "                            success = enviar_alerta_servidor(payload)\n",
    "                            if success:\n",
    "                                print(f\"[ALERTA] Enviado com sucesso: {payload}\")\n",
    "                                emitir_som_alerta()\n",
    "                                registrar_log(alerta_atual, description)\n",
    "                                alerta_enviado = True\n",
    "                                last_alert_time = agora\n",
    "                            else:\n",
    "                                print(f\"[ERRO] Não foi possível enviar alerta: {payload}\")\n",
    "                    else:\n",
    "                        alerta_enviado = False\n",
    "\n",
    "            cv2.putText(frame, \"Pressione ESC para sair\", (10, 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "            cv2.imshow(\"Detector de Gestos em Ambiente Escuro\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Erro geral no processamento de vídeo: {e}\")\n",
    "    finally:\n",
    "        if cap:\n",
    "            cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Detector de Gestos em Baixa Luminosidade\")\n",
    "    parser.add_argument(\"--video\", \"-v\", help=\"Caminho para arquivo de vídeo de teste. Se omitido, usa webcam.\")\n",
    "    parser.add_argument(\"--camera\", \"-c\", type=int, default=0, help=\"Índice da webcam (padrão 0).\")\n",
    "    parser.add_argument(\"--delay\", \"-d\", type=int, default=DELAY_SEGUNDOS,\n",
    "                        help=f\"Delay mínimo entre alertas consecutivos em segundos (padrão {DELAY_SEGUNDOS}).\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    global DELAY_SEGUNDOS\n",
    "    DELAY_SEGUNDOS = args.delay\n",
    "\n",
    "    if args.video:\n",
    "        if not os.path.isfile(args.video):\n",
    "            print(f\"[ERROR] Arquivo de vídeo não encontrado: {args.video}\")\n",
    "            sys.exit(1)\n",
    "        source = args.video\n",
    "    else:\n",
    "        source = args.camera\n",
    "\n",
    "    print(f\"[INFO] Iniciando detecção. Fonte: {source}. Delay = {DELAY_SEGUNDOS}s\")\n",
    "    processar_fluxo(source)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
